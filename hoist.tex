\documentclass{sig-alternate}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{graphviz}
\usepackage{auto-pst-pdf}
\usepackage{etoolbox}
\usepackage{flushend}
\usepackage{needspace}

\makeatletter
\preto{\@verbatim}{\topsep=1pt \partopsep=0pt}
\makeatother

\pagenumbering{arabic}

\begin{document}
\def \SCoP {SCoP}
\def \GCC {GCC}
\def \LLVM {LLVM}
\def \SESE {SESE}
\def \CFG {CFG}
\def \SSA {SSA}
\def \scev {scev}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\title{GVN-Hoist: Hoisting Computations from Branches}

\toappear{
   \hrule \vspace{5pt}
   LLVM-dev 2016
}
\numberofauthors{2}

\author{
\alignauthor
Aditya Kumar\\
       \affaddr{Samsung Austin R\&D Center}\\
       \email{aditya.k7@samsung.com}
\alignauthor
Sebastian Pop\\
       \affaddr{Samsung Austin R\&D Center}\\
       \email{s.pop@samsung.com}
}

\maketitle
\begin{abstract}
  Code hoisting identifies identical computations across the program with the
  help of a Global Value Numbering (GVN) analysis, identifies a hoisting
  position that dominates all the identical computations and in which all
  operands are avaialable, duplicates one of the expressions in the hoisting
  position, and removes all the computations now redundant in their original
  position.

  Code hoisting is often confused with CSE (Common Subexpression Elimination)
  although hoisting is not bound to find redundancies within a single basic
  block.  Code hoisting could also be confused with Partial Redundancy
  Elimination (PRE) or even with Global Common Subexpression Elimination (GCSE)
  although the main goal of code hoisting is not to remove redundancies: code
  hoisting effectively exposes redundancies and enables other passes like LICM
  to remove more redundancies.  The main goal of code hoisting is to reduce code
  size with the added benefit of exposing more instruction level parallelism and
  reduced register pressure.
\end{abstract}

\section{Introduction}

Classical scalar optimizations like CSE \cite{dragonbook} work very well on
single basic blocks.  With time, we have seen the transition to more complex
passes like GCSE that work across basic blocks, or other passes like the
macroblock formation that create a region within


Why hoisting expressions:
\begin{itemize}
\item OOO processors: good for speculative execution of branches
\item more ILP for in-order processors
\item code size
\item optimize for register pressure
\item improve inlining heuristics
\end{itemize}

\begin{enumerate}
\item Code hoisting in adjacent blocks in a diamond/triangle like structure.
\item O(n) Algorithm.
\item Hoisting equivalent computations in non-sibling BBs.
\item Hoisting across switch blocks.
\item Hoisting to improve PRE.
\item Hoisting to reduce critical path in OoO execution.
\item Ranking/Wavefront algorithm to hoist across switch blocks.
\end{enumerate}

\subsection{Enabling LICM by code-hoisting}

\begin{verbatim}
loop:
if (a)
  i1;
else
  i1;
\end{verbatim}

Here i1 is redundant and can be hoisted out of loop. But the LICM will
not do because it does not reason about instructions in the
conditional.  By code-hoisting i1 will be hoisted out of conditional
which will benefit the LICM.

\subsection{Improving the Inliner heuristics}
Reducing the number of instructions also reduces the inlining cost and
hence improves the inliner heuristics.

\subsection{Improving vectorization}
It will also benefit vectorizer by reducing the number
of basic blocks, should all the instructions in conditional get hoisted.



\section{Related Work}

A lot of bug reports in GCC and LLVM bugzillas, no papers on this topic yet.

Code hoisting does not remove redundancies by itself but it enables
removal of redundancies by other passes.  e.g., Enable inlining.


graph algorithms \cite{tarjan},
SSA \cite{cytron}
GVN \cite{rosen1988global,click1995global}
CFG, DOM \cite{dragonbook}
SESE, SEME \cite{sese}
MemorySSA \cite{novillo2007memory}

\subsection{Global Value Numbering}

\newpage

\section{Code hoisting}

\subsection{Overview}

Code hoisting can also reduce the critical path length of execution in out of
order machines. As more instructios are available at the hoisting point, the
hardware has more instructions to reorder. Following example illustrates how
hoisting can improve performance by exposing more ILP.

\begin{verbatim}
float foo(float d, float min, float max, float a)
{
  float tmin, tmax, inv;

  inv = 1.0f / d;
  if (inv >= 0) {
    tmin = (min - a) * inv;
    tmax = (max - a) * inv;
  } else {
    tmin = (max - a) * inv;
    tmax = (min - a) * inv;
  }
  return tmax + tmin;
}
\end{verbatim}

In this program the computations of tmax and tmin are identical to the
computations of tmin and tmax of sibling branch respectively. Both tmax and tmin
depends on inv which depends on a division operation which is generally more
expensive than the addition, subtraction and multiplication operations. The
total latency of computation across each branch is:

O(div) + 2(O(sub) + O(mul))
Or for out of order processors with two add units and two multiply units:
O(div) + O(sub) + O(mul)

Now if the computation of tmax and tmin are hoisted outside the
conditionals, the C code version would look like this:
\begin{verbatim}
float foo(float d, float min, float max, float a)
{
  float tmin, tmax, tmin1, tmax1, inv;

  tmin1 = (min - a);
  tmax1 = (max - a);

  inv = 1.0f / d;
  tmin1 = tmin1 * inv;
  tmax1 = tmax1 * inv;

  if (inv >= 0) {
    tmin = tmin1;
    tmax = tmax1;
  } else {
    tmin = tmax1;
    tmax = tmin1;
  }

  return tmax + tmin;
}

\end{verbatim}

In this code the two subtractions and the division operations can be executed in
parallel because there are no dependencies among them. So the total number of
cycles will be max(O(div), O(sub)) + O(mul) = O(div) + O(mul); since O(div) is
usually much greater than O(sub) \cite{x86,aarch64}

Of course, a partial redundancy elimination pass could just remove the entire
if-block because final operation is an addition (asociative under fast math).

\begin{verbatim}
float foo(float d, float min, float max, float a)
{
  float tmin1, tmax1, inv;

  tmin1 = (min - a);
  tmax1 = (max - a);

  inv = 1.0f / d;
  tmin1 = tmin1 * inv;
  tmax1 = tmax1 * inv;

  return tmax1 + tmin1;
}
\end{verbatim}

\subsubsection{Hoisting scalars}
Scalars are the easiest to hoist because we do not have to analyze
them for aliasing memory references. As long as all the operands are
available (which in SSA form we do, or may be there are chained
dependencies), the scalar can be hoisted. Care must be taken in case
of hoisting scalars too far, as that may increase register pressure
and result in spills. For example hoisting a scalar past a call. In
that case the call may result in save and restore of the register the
scalar may be defined to. In our current implementation we do not
hoist scalars past a call. Another way to mitigate this problem is be
to reinstantiate (rematerialize) the computation after a call (may be
as a different pass).

\subsubsection{Hoisting loads}
In order to value number stores, we value number (hash) the address from where
the value is to be loaded. Then we need to compute the hoisting point just like
we did for the scalars. At the hoisting point we compute if the operands to the
load (an address) is available. If it is not available we can try to compute the
addresss if that is possible.  Along the path from current position of the load
instruction through the hoiting point, we find if there are aliasing stores, we
find if any of the basic blocks are landing pads or targets of indirect
branches. In those cases we discard the candidate. Since the load increases the
register pressure by one (unless the operand to load becomes dead at the load),
we evaluate if it is beneficial to hoist the load.

\subsubsection{Hoisting stores}
In order to value number stores, we value number (hash) the address as well as
the value to be stored to that address. For the legality, we need to check the
dependency requirements just like hoisting loads. We need to check that the
operands of store are available at the hoisting point, that there are no
aliasing loads or store along the path from the current position through the
hoisting point and, none of the basic blocks along the path are landing pads.
Once all the legality checks are satisfied, it is a good candidate to be
hoisted.

\subsubsection{Hoisting calls}
Calls can be hoisted by value-numbering all the arguments. For safety
we have to check that there are no other side-effects between a call and
its hoisting point, just like loads and stores.




\subsection{Algorithm}
A good full page.

\subsubsection{Hoisting bottom up with optimistic approach}
Optimistic means collect the set of all potential redundancies and
then discard the bad ones.

Bottom up: Sort the basic blocks of potentially redundant computations
based on DFS-in numbers.  TODO: Explain why sorting by DFS-in numbers.
Then start evaluating the safety checks for first two, if good then
move to second one. That way we can even partially hoist computations
should we find that we cannot remove all the redundant computations.

We can also split the set of to partially hoist multiple times, if
hoisting globally is not possible.

In the case when more than one computation from the same basic block
shows up as redundant.

e.g.
\begin{verbatim}
BB1
load a;
....
store .;
....
load a;


BB2
load a

BB0 -> BB1
BB0 -> BB2
\end{verbatim}

In this case both the loads from BB1 will show up as redundant
(according to the current algorithm), but the complete hoising will
fail as the second load in BB1 is not safe to hoist. By following the
bottom-up approach, the sorted list of BBs will appear like this:

{ BB1, BB2(first load), BB2(second load) }

Now we will start evaluating the safety of BB1-l1 and BB2-l2 which
will pass, then BB12-l1 and BB2-l2 will fail.  So we can revert back
to BB12-l1 and hoist them to BB0. Doing the top down approach and
finding the partial set to hoist instructions partially would result
in a combinatorial explosion.

GCC: 23286 has interesting test cases.

\subsubsection{Partition the list of hoisting candidates to maximize hoisting}
\label{subsec:partition}
The set of candidates are sorted in the order of their DFS-in
numbers. So that candidates close to each other in the list are also
closer (??) in the CFG.

In the case where all the candidates cannot be hoisted at a common
hoist point because of:
\begin{enumerate}
\item Safety conditions are not met.
\item Live range would increase too much.
\end{enumerate}

In order to hoist a subset of identical instructions, we partition the
list of all candidates in a way to maximise the total number of
hoistings.  By sorting the list of all the candidates in the
increasing order of their DFS-in numbers, we make sure that candidates
closer in the list have their common dominator nearby.

Essentially,
abs(DFSIn(I1) - DFSIn(I2)) < abs(DFSIn(I1) - DFSIn(I3))
=> bbDist(I1, nearest-common-dom(I1, I2)) <= bbDist(I1, nearest-common-dom(I1, I3))

This means for candidates closer to each other w.r.t. DFS numbers:
\begin{enumerate}
\item would make fewer checks for legality and profitability.
\item hoisting point will be closer so, the intersection of live-range of the
  instruction with other instructions will be minimal.
\end{enumerate}

In our current implementation we partition the list at the point where the
legality/profitability checks fail.

TODO: Put an example to illustrate the point.

\subsection{Cost models}

\subsubsection{Reduce register pressure}
\label{hoist:reg-pressure}
Following example explains how code hoisting can actually reduce the register pressure.
Consider the following example where the labels prefixed with 'p' represent the position of
instruction in a basic block (names prefixed with bb).

\begin{verbatim}
bb0: p0: b = ...
bb1: p1: c = ...
bb2: p2: if (c) jump bb3 else jump bb4
bb3: p3: a0 = b + c
bb4: p4: a1 = b + c
bb5: p5: d = phi {a0(bb3), a1(bb4)}

If we measure distance(px, py) as total instruction
count in the path from the position of px to py

old-live-range = max(distance(p0, p3) + distance(p1, p3) ,
                     distance(p0, p4) + distance(p1, p4))
                 + distance (p3, p5)
new-live-rance = distance(p0, p2) + distance(p1, p2)
                 + distance (p2, p5)
\end{verbatim}

If the new live-range is less than the old one it will be a good candidate
for hoist. There are cases when both the ranges will be same:
\begin{enumerate}
  \item There is only one operand on the right hand side e.g., an assignment operation.
  \item One of the operands is not a Instruction/Register.
\end{enumerate}

In a special case where the instruction to be hoisted has the last use of its
operands then the code hoisting will always reduce the register pressure if it
has two register operands because the gain in live-range will be in the ratio of
2:1. Based on the above formulae we can also deduce that, as long as there is
one register operand in the right hand side with its last use, code hoisting
will either decrease or maintain the register pressure.

\subsubsection{In the presence of calls}
Hoisting scalars across calls is tricky because it can increase the number of
spills. During the frame lowering of calls, the argument registers, in general,
the caller saved registers are saved because they might be modified by the
callee and after the call they are restored \cite{frame-lowering}. So before the
call, the register pressure is high because the number of available registers
are reduced by the number of caller saved registers. In that situation if a
computation is hoisted across the call, that would increase the total number of
registers required by one, thus contributing to the register pressure.

However, in the two special cases discussed in Section-\ref{hoist:reg-pressure},
it will be okay to hoist because the regiter pressure would not change.

Hoisting memory references also require precise analysis of all the memory
addresses accessed by the call. In our implementation, since we only analyze the
callee declaration the analysis is very conservative. In the presence of pure
calls, loads can be hoisted but stores can't. Also, if the call throws exceptions,
or it it may not return, memory references cannot be hoisted.

\subsubsection{Hoisting too far away}
When we load a value from memory, we require an extra register to keep the value
around. Hoisting a load means we need to keep the value alive for a longer
period. That could result in spills later in the register allocation.

Also, if there are several instructions in between the hoisting point and the
instruction to be hoisted, the instruction to be hoisted crosses several
instructions while hoisting, it means we are adding one register to all the
live-ranges spanning the instructions. That could result in spills. In the
current implementation we choose to hoist if the number of instructions crossed
is below a threshold. Ideally, it should be okay to hoist all the instructions
and a later live-range-splitting pass should make the right decision of
rematerializing the instruction should it be beneficial to do so. But the
current live-range splitting pass of llvm is not making the optimial decision
and we have found spills if the threshold is exceeded. The threshold was
computed as a result of tuning the llvm testsuite \cite{llvm-nightly} and spec
benchmark \cite{Henning2000}.

\begin{enumerate}
\item When the hoist point is too far.
\item When the number of instructions we may cross is very high.
\end{enumerate}


\subsection{Other Approaches}

\subsubsection{Triangle approach}
This is the most basic approach to code-hoisting when the instructions are
hoisted to immediate parent in a diamond like structure. When there are
identical computations in both the branches of a conditional, and all the
legality checks are met, the instruction can be hoisted to the predecessor basic
block. This approach is simple to implement and has minimal impact on the
register pressure.

\subsubsection{Pessimistic approach}
To extend the triangle approach to the entire function, the algorithm traverses
the basic blocks in the invers depth-first order. All the leaf nodes are visited
before the non-leaf nodes because instructions are hoisted upwards. We start
from a branch and collect the GVN of all the instructions. Then in the sibling
basic block we find if there are any identical computations. Once we find an
identical computation we try to hoist it to the nearest common dominator which
is the immediate predecessor of both the basic blocks. We traverse the basic
block from top to down so that the once an instruction is hoisted it creates
opportunities for other dependent instructions. After all the sibling basic
blocks have all the identical computations hoisted, we continue the hoisting
process with their parent and its sibling of their parent until we reach the
beginning of the function.

\subsubsection{Optimistic approach}
In this approach, the goal is to maximise the total number of hoistings in the
entire function.  This algorithm is very useful when optimizing for code-size.
We see a lot of computations hoisted (see
Section~\ref{sec:experimental-results}. In order to do that, we collect the GVN
of all the instructions in the function. After that we iterate on the list of
instructions having identical GVN. After that we find the common dominator
dominating all the identical computations and try to hoist the instruction in
that basic block, if feasible. Many times it is not possible to hoist all the
instructions to one common dominator, due to legality/profitability
constraints. In those cases, the algorithmn would partion the list of
computations a partially hoist a set of computations to their common
dominator. For more details see Section~\ref{subsec:partition}.


\subsubsection{pros,cons}
Naturally, the amount of hoisting depends on the generality of the GVN
algorithm. Current llvm GVN implementation finds out equivalence between
dependent instructions to some extent.

\subsubsection{PRE based hoisting}

\newpage

\section{Experimental Evaluation}
\label{sec:experimental-results}

\subsection{Comparative analysis of different approaches to hoisting}


\section{Conclusion and Future Work}

\bibliographystyle{abbrv}
{\small
\bibliography{Bibliography}
}
\end{document}
